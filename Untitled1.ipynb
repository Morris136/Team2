{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONl2ufR2BCGrG82E3BbaoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morris136/Team2/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”§ å®‰è£ Gemini å¥—ä»¶\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "# ğŸ§  åŒ¯å…¥å‡½å¼åº«\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# ğŸ”‘ è¨­å®š API é‡‘é‘°ï¼ˆè«‹æ›æˆä½ çš„é‡‘é‘°ï¼‰\n",
        "genai.configure(api_key=\"YOUR_API_KEY\")  # â† â† â† è«‹å°‡æ­¤è™•æ›¿æ›ç‚ºä½ è‡ªå·±çš„ API Key\n",
        "\n",
        "# ğŸš€ åˆå§‹åŒ–æ¨¡å‹\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "# --- Step 1: åˆå§‹æç¤º ---\n",
        "original_prompts = [\n",
        "    \"è«‹ç”¨ä¸€å¥è©±è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ã€‚\",\n",
        "    \"åˆ—å‡ºä¸‰å€‹Pythonè³‡æ–™å‹åˆ¥ã€‚\",\n",
        "    \"å¹«æˆ‘å¯«ä¸€å€‹å¯ä»¥åè½‰å­—ä¸²çš„Pythonå‡½æ•¸ã€‚\"\n",
        "]\n",
        "\n",
        "original_outputs = []\n",
        "\n",
        "print(\"ğŸ“Œ åŸå§‹æç¤ºèˆ‡å›æ‡‰ï¼š\")\n",
        "for i, prompt in enumerate(original_prompts, 1):\n",
        "    response = model.generate_content(prompt)\n",
        "    original_outputs.append(response.text)\n",
        "    print(f\"\\nğŸ§  Prompt {i}: {prompt}\\nğŸ’¬ Output:\\n{response.text}\")\n",
        "\n",
        "# --- Step 2: ç²¾ç…‰æç¤º ---\n",
        "refined_prompts = [\n",
        "    \"æ©Ÿå™¨å­¸ç¿’èˆ‡å‚³çµ±ç¨‹å¼è¨­è¨ˆæœ‰ä½•ä¸åŒï¼Ÿè«‹ç°¡å–®æ¯”è¼ƒå¾Œï¼Œç”¨ä¸€å¥è©±å®šç¾©æ©Ÿå™¨å­¸ç¿’ã€‚\",\n",
        "    \"åˆ—å‡ºä¸‰å€‹å¸¸è¦‹ Python è³‡æ–™å‹åˆ¥ï¼Œä¸¦é™„ä¸Šå¯¦éš›ç”¨é€”èˆ‡ç¯„ä¾‹ç¨‹å¼ç¢¼ã€‚\",\n",
        "    \"è«‹å…ˆè§£é‡‹åè½‰å­—ä¸²å¸¸è¦‹çš„æ–¹æ³•ï¼Œå†æä¾›ä¸€å€‹ Python å‡½æ•¸ï¼Œä¸¦é€è¡Œèªªæ˜ã€‚\"\n",
        "]\n",
        "\n",
        "refined_outputs = []\n",
        "\n",
        "print(\"\\nğŸ”§ ç²¾ç…‰æç¤ºèˆ‡æ”¹é€²å›æ‡‰ï¼š\")\n",
        "for i, prompt in enumerate(refined_prompts, 1):\n",
        "    response = model.generate_content(prompt)\n",
        "    refined_outputs.append(response.text)\n",
        "    print(f\"\\nğŸ” Refined Prompt {i}: {prompt}\\nğŸ’¡ Improved Output:\\n{response.text}\")\n",
        "\n",
        "# --- Step 3: åˆ†æ ---\n",
        "analysis = \"\"\"\n",
        "é€éæ‡‰ç”¨å°‘æ¨£æœ¬èˆ‡æ€ç¶­éˆæç¤ºæŠ€å·§ï¼Œæ¨¡å‹å›ç­”çš„æ·±åº¦èˆ‡æ¸…æ™°åº¦é¡¯è‘—æå‡ã€‚åŸå§‹æç¤ºåƒ…ç”¢ç”Ÿç°¡è¦å›æ‡‰ï¼Œç¼ºä¹èƒŒæ™¯èˆ‡æ¨ç†ï¼Œè€Œç²¾ç…‰æç¤ºå¼•å°æ¨¡å‹å±•é–‹æ•˜è¿°ã€èˆ‰ä¾‹èˆ‡èªªæ˜é‚è¼¯æµç¨‹ã€‚ç‰¹åˆ¥æ˜¯åœ¨åè½‰å­—ä¸²å•é¡Œä¸­ï¼Œæ”¹é€²æç¤ºå…ˆè¬›è§£å¸¸è¦‹åšæ³•ï¼Œå†æä¾›è¨»è§£å®Œæ•´çš„ç¨‹å¼ç¢¼ï¼Œå±•ç¾å‡ºæ›´é«˜çš„æ•™å­¸åƒ¹å€¼èˆ‡ç†è§£åŠ›ã€‚é€™ä¸åƒ…æå‡äº†å›ç­”çš„å¯¦ç”¨æ€§ï¼Œä¹Ÿé™ä½äº†åå·®èˆ‡èª¤è§£é¢¨éšªï¼Œç¬¦åˆé«˜å“è³ªæç¤ºè¨­è¨ˆçš„ç›®æ¨™ã€‚\n",
        "\"\"\"\n",
        "print(\"\\nğŸ“ˆ åˆ†æï¼ˆ100â€“200 å­—ï¼‰:\")\n",
        "print(analysis)\n",
        "\n",
        "# --- Step 4: å„²å­˜å ±å‘Š ---\n",
        "report_path = \"gemini_prompt_report.txt\"\n",
        "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"ğŸ“Œ åŸå§‹æç¤ºèˆ‡è¼¸å‡ºï¼š\\n\")\n",
        "    for i in range(len(original_prompts)):\n",
        "        f.write(f\"\\nPrompt {i+1}: {original_prompts[i]}\\n\")\n",
        "        f.write(f\"Output:\\n{original_outputs[i]}\\n\")\n",
        "\n",
        "    f.write(\"\\n\\nğŸ”§ ç²¾ç…‰æç¤ºèˆ‡æ”¹é€²è¼¸å‡ºï¼š\\n\")\n",
        "    for i in range(len(refined_prompts)):\n",
        "        f.write(f\"\\nRefined Prompt {i+1}: {refined_prompts[i]}\\n\")\n",
        "        f.write(f\"Improved Output:\\n{refined_outputs[i]}\\n\")\n",
        "\n",
        "    f.write(\"\\n\\nğŸ“Š åˆ†æï¼š\\n\")\n",
        "    f.write(analysis)\n",
        "\n",
        "print(f\"\\nâœ… å ±å‘Šå·²å„²å­˜ç‚ºï¼š{report_path}\")\n"
      ],
      "metadata": {
        "id": "FONwqLOQngU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "é€éæç¤ºå·¥ç¨‹æŠ€å·§ï¼ˆå¦‚å°‘æ¨£æœ¬èˆ‡æ€ç¶­éˆï¼‰ï¼Œæˆ‘å€‘é¡¯è‘—æ”¹å–„äº†æ¨¡å‹çš„è¼¸å‡ºå“è³ªã€‚åŸå§‹æç¤ºé€šå¸¸ç”¢ç”Ÿç°¡ç•¥ã€æœªèªªæ˜åŸå› çš„å›ç­”ï¼Œç¼ºä¹æ•™å­¸æ€§èˆ‡æ·±åº¦ã€‚è€Œç²¾ç…‰å¾Œçš„æç¤ºé€éå¼•å°æ¨¡å‹é€æ­¥æ€è€ƒã€è§£é‡‹æ¦‚å¿µèˆ‡èˆ‰ä¾‹ï¼Œè®“å›ç­”æ›´å…·é‚è¼¯æ€§èˆ‡æ¸…æ™°åº¦ã€‚ä¾‹å¦‚åœ¨è³‡æ–™å‹åˆ¥çš„å•é¡Œä¸­ï¼Œæ¨¡å‹ä¸å†åƒ…åˆ—å‡ºåç¨±ï¼Œè€Œæ˜¯é™„ä¸Šç”¨é€”èˆ‡ç¨‹å¼ç¢¼ï¼Œä½¿å›æ‡‰æ›´å…·å¯¦ç”¨æ€§ã€‚é€™äº›æ”¹é€²æ¸›å°‘äº†æ¨¡ç³Šæˆ–ç‰‡æ®µå¼å›ç­”ï¼Œä¹Ÿæå‡äº†å°è©±çš„æ•™è‚²èˆ‡åƒè€ƒåƒ¹å€¼ã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "UHKFPw72lef2"
      }
    }
  ]
}